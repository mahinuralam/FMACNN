# FMACNN: Federated Multi-Attention CNN Framework for Artificial Image Detection

## Description

This project introduces the **Federated Multi-Attention CNN (FMACNN)** framework designed to enhance the detection of artificially generated images while preserving data privacy. The FMACNN framework integrates **Federated Learning (FL)** and **Multi-Attention CNNs**, offering a decentralized, privacy-preserving solution for detecting synthetic images generated by advanced AI models such as GANs and diffusion transformers.

The framework leverages multi-attention mechanisms to improve the model's ability to focus on critical features of images, increasing detection accuracy. This system is deployed across edge devices to ensure privacy and scalability, making it highly efficient for real-world applications. Additionally, the **RealAIGI dataset**, which consists of a mix of real and synthetic AI-generated images, is used to train and evaluate the model.

### Key Contributions:
- We propose the FMACNN framework that integrates advanced attention mechanisms with federated learning to enhance the detection of artificially generated images. By utilizing AI-generated images directly from edge devices, the framework adapts to increasingly realistic synthetic content produced by GANs. Designed for decentralized training, it ensures robust data privacy while optimizing detection accuracy.
- Proposed a Multi-Attention CNN model that surpasses SOTA performance by leveraging multiple attention layers to emphasize critical features and regions within the input data while maintaining a lightweight architecture. The FMACNN framework minimizes computational overhead, ensures low execution time, and achieves faster convergence to high accuracy, making it ideal for deployment in resource-constrained environments.
- We developed the RealAIGI dataset, featuring a well-balanced mix of real and highly realistic AI-generated images. Leveraging the benchmark Diffusion Transformer model (Sora), this dataset provides diverse and challenging training scenarios that surpass existing benchmarks in authenticity, ensuring more effective artificial image detection.
- The proposed framework is rigorously tested and benchmarked against SOTA approaches using CIFAKE, FaceForensics++ (FF++), and the newly introduced RealAIGI dataset. This comprehensive evaluation validates its reliability, efficiency, and superiority in detecting artificially generated images across diverse scenarios.

## Key Features
- **Federated Learning**: Decentralized training across multiple edge devices, ensuring privacy and efficient model aggregation.
- **Multi-Attention Mechanisms**: Attention layers integrated into CNNs to emphasize critical features in images, improving detection accuracy.
- **Efficient and Scalable**: Optimized for resource-constrained environments with minimal computational overhead.

## Dataset

- **RealAIGI Dataset**: A balanced dataset of real and AI-generated images, used for training and testing the detection model. It includes 10,015 images across 17 categories, generated using the **Sora Diffusion Transformer** model.
- **Benchmark Datasets**: **CIFAKE** and **FaceForensics++** are also used for evaluation to ensure the model's generalization and robustness across different types of artificial images.

## Results

- The proposed FMACNN framework outperforms state-of-the-art models, achieving **99.12% accuracy**, **98.92% precision**, and **99.05% recall** across multiple datasets.
- The model's performance is tested in a federated learning environment and demonstrates superior scalability and resource efficiency compared to existing frameworks.

## Some of the results

![image](https://github.com/user-attachments/assets/13f6e507-cc62-41e6-8494-e099b86d5109)

![image](https://github.com/user-attachments/assets/2b5556f4-a42a-49aa-9128-96d292d1f3d3)

![image](https://github.com/user-attachments/assets/4cb3f085-0ed8-4126-8cc0-5a8ab95ee4cd)
