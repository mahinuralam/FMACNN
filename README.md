# FMACNN: Federated Multi-Attention CNN Framework for Artificial Image Detection

## Project Description

This project introduces the **Federated Multi-Attention CNN (FMACNN)** framework designed to enhance the detection of artificially generated images while preserving data privacy. The FMACNN framework integrates **Federated Learning (FL)** and **Multi-Attention CNNs**, offering a decentralized, privacy-preserving solution for detecting synthetic images generated by advanced AI models such as GANs and diffusion transformers.

The framework leverages multi-attention mechanisms to improve the model's ability to focus on critical features of images, increasing detection accuracy. This system is deployed across edge devices to ensure privacy and scalability, making it highly efficient for real-world applications. Additionally, the **RealAIGI dataset**, which consists of a mix of real and synthetic AI-generated images, is used to train and evaluate the model.

### Key Contributions:
- **FMACNN Framework**: Integrates federated learning with multi-attention CNNs, ensuring high detection accuracy while preserving user privacy.
- **RealAIGI Dataset**: A new dataset for artificial image detection, including AI-generated images using the Sora Diffusion Transformer model, aimed at enhancing training scenarios.
- **Superior Performance**: Achieved 99.12% accuracy in detecting artificial images, surpassing current state-of-the-art models on benchmark datasets like **CIFAKE** and **FaceForensics++**.

## Key Features
- **Federated Learning**: Decentralized training across multiple edge devices, ensuring privacy and efficient model aggregation.
- **Multi-Attention Mechanisms**: Attention layers integrated into CNNs to emphasize critical features in images, improving detection accuracy.
- **Efficient and Scalable**: Optimized for resource-constrained environments with minimal computational overhead.

## Dataset

- **RealAIGI Dataset**: A balanced dataset of real and AI-generated images, used for training and testing the detection model. It includes 10,015 images across 17 categories, generated using the **Sora Diffusion Transformer** model.
- **Benchmark Datasets**: **CIFAKE** and **FaceForensics++** are also used for evaluation to ensure the model's generalization and robustness across different types of artificial images.

## Results

- The proposed FMACNN framework outperforms state-of-the-art models, achieving **99.12% accuracy**, **98.92% precision**, and **99.05% recall** across multiple datasets.
- The model's performance is tested in a federated learning environment and demonstrates superior scalability and resource efficiency compared to existing frameworks.

## Some of the results

![image](https://github.com/user-attachments/assets/13f6e507-cc62-41e6-8494-e099b86d5109)


![image](https://github.com/user-attachments/assets/2b5556f4-a42a-49aa-9128-96d292d1f3d3)


## Usage

To use the FMACNN framework for artificial image detection, follow these steps:
1. **Training**: The model is trained using federated learning across edge devices, ensuring data privacy.
2. **Detection**: The trained model can be used to classify images as real or AI-generated.










![image](https://github.com/user-attachments/assets/4cb3f085-0ed8-4126-8cc0-5a8ab95ee4cd)
